{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4c7cd2-2b50-4ceb-b6f1-aa2769040602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T12:29:58.470036Z",
     "start_time": "2022-04-01T12:29:58.456997Z"
    }
   },
   "source": [
    "# Perform Backtest - Operational Congestion Management\n",
    "1. Load input prepared in 'Combine input'\n",
    "1. Perform backtest\n",
    "1. Store backtest-output as csv in 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56909374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T14:34:14.914805Z",
     "start_time": "2022-04-01T14:34:14.886772Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import cufflinks\n",
    "\n",
    "cufflinks.go_offline()\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "from openstef.pipeline.train_create_forecast_backtest import (\n",
    "    train_model_and_forecast_back_test,\n",
    ")\n",
    "from openstef.metrics.figure import plot_feature_importance\n",
    "from openstef.data_classes.model_specifications import ModelSpecificationDataClass\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788e725-9e6b-448c-b736-ebc12b20c6b7",
   "metadata": {},
   "source": [
    "## Do backtest of uncurtailed load\n",
    "1. Compare backtest results with operational results to ensure validity of backtest.\n",
    "2. Change features of backtest to include generated wind-energy and/or solar-energy (of at least a big PV park)\n",
    "3. Compare results of:\n",
    "    - operational predictions\n",
    "    - backtest original\n",
    "    - backtest perfect wind\n",
    "    - backtest perfect solar\n",
    "    - backtest perfect wind+solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b97e00-23d6-4c59-98f5-df43cb53c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv(\"input/prepped_inputs.csv\", index_col=0, parse_dates=True)\n",
    "predictors = pd.read_csv(\"input/predictors.csv\", index_col=0, parse_dates=True).iloc[\n",
    "    :, 1:\n",
    "]  # first column only as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f46ef4f8-c84d-48be-b4ef-eecc9eeee241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give variables clear names\n",
    "# Uncurtailed load\n",
    "unc_load = inputs[\"Load_corrected_for_curtailment\"]\n",
    "# Operational Predictions (nb. using a different correction for curtailment)\n",
    "op_preds = inputs[\"Day_ahead_forecast\"]\n",
    "# True windenergy generation\n",
    "wind_ref = inputs[\"Wind_reference\"]\n",
    "# PV reference profile\n",
    "pv_ref = inputs[\"PV_reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a59ab6a-82ea-4a3b-8e0e-40bc1a82b91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>clouds</th>\n",
       "      <th>radiation</th>\n",
       "      <th>temp</th>\n",
       "      <th>winddeg</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>windspeed_100m</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>sjv_E1A</th>\n",
       "      <th>sjv_E1B</th>\n",
       "      <th>sjv_E1C</th>\n",
       "      <th>sjv_E2A</th>\n",
       "      <th>sjv_E2B</th>\n",
       "      <th>sjv_E3A</th>\n",
       "      <th>sjv_E3B</th>\n",
       "      <th>sjv_E3C</th>\n",
       "      <th>sjv_E3D</th>\n",
       "      <th>sjv_E4A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-25 12:30:00+00:00</th>\n",
       "      <td>1.59</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1699921.750</td>\n",
       "      <td>8.828156</td>\n",
       "      <td>165.572105</td>\n",
       "      <td>5.257527</td>\n",
       "      <td>7.570897</td>\n",
       "      <td>102528.937500</td>\n",
       "      <td>0.846426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25 12:45:00+00:00</th>\n",
       "      <td>2.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1683326.125</td>\n",
       "      <td>8.903656</td>\n",
       "      <td>156.779652</td>\n",
       "      <td>4.707029</td>\n",
       "      <td>6.780270</td>\n",
       "      <td>102524.113281</td>\n",
       "      <td>0.841932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25 13:00:00+00:00</th>\n",
       "      <td>2.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1666730.500</td>\n",
       "      <td>8.979156</td>\n",
       "      <td>147.987198</td>\n",
       "      <td>4.156531</td>\n",
       "      <td>5.989644</td>\n",
       "      <td>102519.289062</td>\n",
       "      <td>0.837438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25 13:15:00+00:00</th>\n",
       "      <td>3.36</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1650134.875</td>\n",
       "      <td>8.924049</td>\n",
       "      <td>143.610104</td>\n",
       "      <td>3.929555</td>\n",
       "      <td>6.120461</td>\n",
       "      <td>102532.164062</td>\n",
       "      <td>0.837671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25 13:30:00+00:00</th>\n",
       "      <td>4.83</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1633539.250</td>\n",
       "      <td>8.868942</td>\n",
       "      <td>139.233009</td>\n",
       "      <td>3.702580</td>\n",
       "      <td>6.251278</td>\n",
       "      <td>102545.039062</td>\n",
       "      <td>0.837904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           load  clouds    radiation      temp     winddeg  \\\n",
       "Time                                                                         \n",
       "2021-02-25 12:30:00+00:00  1.59   100.0  1699921.750  8.828156  165.572105   \n",
       "2021-02-25 12:45:00+00:00  2.09   100.0  1683326.125  8.903656  156.779652   \n",
       "2021-02-25 13:00:00+00:00  2.72   100.0  1666730.500  8.979156  147.987198   \n",
       "2021-02-25 13:15:00+00:00  3.36   100.0  1650134.875  8.924049  143.610104   \n",
       "2021-02-25 13:30:00+00:00  4.83   100.0  1633539.250  8.868942  139.233009   \n",
       "\n",
       "                           windspeed  windspeed_100m       pressure  humidity  \\\n",
       "Time                                                                            \n",
       "2021-02-25 12:30:00+00:00   5.257527        7.570897  102528.937500  0.846426   \n",
       "2021-02-25 12:45:00+00:00   4.707029        6.780270  102524.113281  0.841932   \n",
       "2021-02-25 13:00:00+00:00   4.156531        5.989644  102519.289062  0.837438   \n",
       "2021-02-25 13:15:00+00:00   3.929555        6.120461  102532.164062  0.837671   \n",
       "2021-02-25 13:30:00+00:00   3.702580        6.251278  102545.039062  0.837904   \n",
       "\n",
       "                           rain  ...   sjv_E1A   sjv_E1B   sjv_E1C   sjv_E2A  \\\n",
       "Time                             ...                                           \n",
       "2021-02-25 12:30:00+00:00   NaN  ...  0.000028  0.000025  0.000021  0.000033   \n",
       "2021-02-25 12:45:00+00:00   NaN  ...  0.000028  0.000025  0.000021  0.000033   \n",
       "2021-02-25 13:00:00+00:00   NaN  ...  0.000027  0.000025  0.000022  0.000033   \n",
       "2021-02-25 13:15:00+00:00   NaN  ...  0.000027  0.000025  0.000022  0.000033   \n",
       "2021-02-25 13:30:00+00:00   NaN  ...  0.000027  0.000025  0.000022  0.000032   \n",
       "\n",
       "                            sjv_E2B   sjv_E3A   sjv_E3B   sjv_E3C   sjv_E3D  \\\n",
       "Time                                                                          \n",
       "2021-02-25 12:30:00+00:00  0.000031  0.000056  0.000046  0.000046  0.000030   \n",
       "2021-02-25 12:45:00+00:00  0.000031  0.000057  0.000047  0.000047  0.000030   \n",
       "2021-02-25 13:00:00+00:00  0.000031  0.000057  0.000046  0.000046  0.000030   \n",
       "2021-02-25 13:15:00+00:00  0.000031  0.000057  0.000046  0.000046  0.000031   \n",
       "2021-02-25 13:30:00+00:00  0.000031  0.000056  0.000046  0.000046  0.000030   \n",
       "\n",
       "                           sjv_E4A  \n",
       "Time                                \n",
       "2021-02-25 12:30:00+00:00      0.0  \n",
       "2021-02-25 12:45:00+00:00      0.0  \n",
       "2021-02-25 13:00:00+00:00      0.0  \n",
       "2021-02-25 13:15:00+00:00      0.0  \n",
       "2021-02-25 13:30:00+00:00      0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Target and Predictors\n",
    "shared_input_data = pd.DataFrame(unc_load).merge(\n",
    "    predictors, left_index=True, right_index=True\n",
    ")\n",
    "# Target column should be called 'load\n",
    "shared_input_data = shared_input_data.rename(\n",
    "    columns=dict(Load_corrected_for_curtailment=\"load\")\n",
    ")\n",
    "shared_input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9b89c-463e-4f47-bcfa-5ac58e69ebfc",
   "metadata": {},
   "source": [
    "## Do the backtests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a186e1b1-9753-4a75-b9d9-c679edd0125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up backtests\n",
    "# generic\n",
    "# define properties of training/prediction. We call this a 'prediction_job'\n",
    "shared_pj_elements = dict(\n",
    "    model=\"xgb\",\n",
    "    quantiles=[0.10, 0.30, 0.50, 0.70, 0.90],\n",
    "    horizon_minutes=24 * 60,\n",
    "    resolution_minutes=15,\n",
    "    lat=1,  # should become optional\n",
    "    lon=1,  # should become optional\n",
    "    forecast_type=\"demand\",  # Note, this should become optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ee4739f-dc5b-4b00-b103-6c5f89a12933",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec45946e57934436b1aa8869ddc39a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 19:56.13 [info     ] Found 199 values of constant load (repeated values), converted to NaN value. cleansing_step=repeated_values frac_values=0.005182156714668889 num_values=199 pj_id=0\n",
      "2022-11-29 19:56.13 [info     ] Removed 199 NaN values         num_removed_values=199\n",
      "2022-11-29 19:56.33 [info     ] Postproces in preparation of storing\n",
      "2022-11-29 19:56.41 [info     ] Postproces in preparation of storing\n",
      "2022-11-29 19:56.49 [info     ] Postproces in preparation of storing\n",
      "2022-11-29 19:57.03 [info     ] Postproces in preparation of storing\n",
      "2022-11-29 19:57.09 [info     ] Found 199 values of constant load (repeated values), converted to NaN value. cleansing_step=repeated_values frac_values=0.005182156714668889 num_values=199 pj_id=1\n",
      "2022-11-29 19:57.09 [info     ] Removed 199 NaN values         num_removed_values=199\n",
      "2022-11-29 19:57.32 [info     ] Postproces in preparation of storing\n",
      "2022-11-29 19:57.40 [info     ] Postproces in preparation of storing\n",
      "2022-11-29 19:57.48 [info     ] Postproces in preparation of storing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m modelspecs \u001b[38;5;241m=\u001b[39m ModelSpecificationDataClass(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mpj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])      \n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# perform the actual backtest\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m forecast, model, train_data, validation_data, test_data \u001b[38;5;241m=\u001b[39m train_model_and_forecast_back_test(\n\u001b[0;32m     52\u001b[0m     pj,\n\u001b[0;32m     53\u001b[0m     modelspecs \u001b[38;5;241m=\u001b[39m modelspecs,\n\u001b[0;32m     54\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m input_df,\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbacktest_specs,\n\u001b[0;32m     56\u001b[0m  )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Write forecast to csv\u001b[39;00m\n\u001b[0;32m     59\u001b[0m forecast\u001b[38;5;241m.\u001b[39mto_csv(result_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\openstef\\pipeline\\train_create_forecast_backtest.py:77\u001b[0m, in \u001b[0;36mtrain_model_and_forecast_back_test\u001b[1;34m(pj, modelspecs, input_data, training_horizons, n_folds)\u001b[0m\n\u001b[0;32m     63\u001b[0m data_with_features \u001b[38;5;241m=\u001b[39m train_model\u001b[38;5;241m.\u001b[39mtrain_pipeline_step_compute_features(\n\u001b[0;32m     64\u001b[0m     input_data\u001b[38;5;241m=\u001b[39minput_data, pj\u001b[38;5;241m=\u001b[39mpj, model_specs\u001b[38;5;241m=\u001b[39mmodelspecs, horizons\u001b[38;5;241m=\u001b[39mtraining_horizons\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# The use of zip allows to take advantage of the lazy estimation mechanisms of Python, especially if the\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# backtest_split_func returns a generator. This can avoid unwanted multiple data copies.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 1. First we retrieve a generator (use of () comprehensive) on (model, forecast, train, val, test)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 2. Then we unzip the result into generators separated by result type (models, forecasts, trains, vals, tests)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m (\n\u001b[0;32m     72\u001b[0m     models_folds,\n\u001b[0;32m     73\u001b[0m     forecast_folds,\n\u001b[0;32m     74\u001b[0m     train_data_folds,\n\u001b[0;32m     75\u001b[0m     validation_data_folds,\n\u001b[0;32m     76\u001b[0m     test_data_folds,\n\u001b[1;32m---> 77\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_model_and_forecast_test_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelspecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbacktest_split_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_with_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbacktest_split_args\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     90\u001b[0m     pd\u001b[38;5;241m.\u001b[39mconcat(forecast_folds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msort_index(),\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mlist\u001b[39m(models_folds),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mlist\u001b[39m(test_data_folds),\n\u001b[0;32m     95\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\openstef\\pipeline\\train_create_forecast_backtest.py:79\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     63\u001b[0m data_with_features \u001b[38;5;241m=\u001b[39m train_model\u001b[38;5;241m.\u001b[39mtrain_pipeline_step_compute_features(\n\u001b[0;32m     64\u001b[0m     input_data\u001b[38;5;241m=\u001b[39minput_data, pj\u001b[38;5;241m=\u001b[39mpj, model_specs\u001b[38;5;241m=\u001b[39mmodelspecs, horizons\u001b[38;5;241m=\u001b[39mtraining_horizons\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# The use of zip allows to take advantage of the lazy estimation mechanisms of Python, especially if the\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# backtest_split_func returns a generator. This can avoid unwanted multiple data copies.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 1. First we retrieve a generator (use of () comprehensive) on (model, forecast, train, val, test)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 2. Then we unzip the result into generators separated by result type (models, forecasts, trains, vals, tests)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m (\n\u001b[0;32m     72\u001b[0m     models_folds,\n\u001b[0;32m     73\u001b[0m     forecast_folds,\n\u001b[0;32m     74\u001b[0m     train_data_folds,\n\u001b[0;32m     75\u001b[0m     validation_data_folds,\n\u001b[0;32m     76\u001b[0m     test_data_folds,\n\u001b[0;32m     77\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;241m*\u001b[39m(\n\u001b[1;32m---> 79\u001b[0m         \u001b[43mtrain_model_and_forecast_test_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelspecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;241m+\u001b[39m (train_data, validation_data, test_data)\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m train_data, validation_data, test_data \u001b[38;5;129;01min\u001b[39;00m backtest_split_func(\n\u001b[0;32m     84\u001b[0m             data_with_features, n_folds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbacktest_split_args\n\u001b[0;32m     85\u001b[0m         )\n\u001b[0;32m     86\u001b[0m     )\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     90\u001b[0m     pd\u001b[38;5;241m.\u001b[39mconcat(forecast_folds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msort_index(),\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mlist\u001b[39m(models_folds),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mlist\u001b[39m(test_data_folds),\n\u001b[0;32m     95\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\openstef\\pipeline\\train_create_forecast_backtest.py:118\u001b[0m, in \u001b[0;36mtrain_model_and_forecast_test_core\u001b[1;34m(pj, modelspecs, train_data, validation_data, test_data)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model_and_forecast_test_core\u001b[39m(\n\u001b[0;32m     99\u001b[0m     pj: PredictionJobDataClass,\n\u001b[0;32m    100\u001b[0m     modelspecs: ModelSpecificationDataClass,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m     test_data: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[0;32m    104\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (OpenstfRegressor, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124;03m\"\"\"Trains the model and forecast on the test set.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m        forecast (pd.DataFrame): The forecast on the test set.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pipeline_step_train_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelspecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     model_forecast \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\openstef\\pipeline\\train_model.py:399\u001b[0m, in \u001b[0;36mtrain_pipeline_step_train_model\u001b[1;34m(pj, model_specs, train_data, validation_data)\u001b[0m\n\u001b[0;32m    394\u001b[0m     valid_hyper_parameters\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;28mdict\u001b[39m(early_stopping_rounds\u001b[38;5;241m=\u001b[39mDEFAULT_EARLY_STOPPING_ROUNDS)\n\u001b[0;32m    396\u001b[0m     )\n\u001b[0;32m    398\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalid_hyper_parameters)\n\u001b[1;32m--> 399\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Gets the feature importance df or None if we don't have feature importance\u001b[39;00m\n\u001b[0;32m    406\u001b[0m model\u001b[38;5;241m.\u001b[39mfeature_importance_dataframe \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mset_feature_importance()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\xgboost\\sklearn.py:961\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    956\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    958\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m    959\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m    960\u001b[0m )\n\u001b[1;32m--> 961\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sciencenotebooktemplate\\lib\\site-packages\\xgboost\\core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_path = Path(\"output\") / str(datetime.datetime.utcnow()).split(\".\")[0].replace(\n",
    "    \" \", \"T\"\n",
    ").replace(\":\", \"-\")\n",
    "os.makedirs(result_path)\n",
    "\n",
    "## Do the backtest\n",
    "backtest_configs = [\n",
    "    dict(\n",
    "        name=\"backtest\",\n",
    "        additional_features=[],\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"perfect_wind\",\n",
    "        additional_features=[wind_ref],\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"perfect_solar\",\n",
    "        additional_features=[pv_ref],\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"perfect_wind_solar\",\n",
    "        additional_features=[wind_ref, pv_ref],\n",
    "    ),\n",
    "]\n",
    "# Define backtest specs\n",
    "\n",
    "# For one week per fold, use:\n",
    "# n_folds = int(len(set(shared_input_data.index.date))/7.) # one week per fold\n",
    "# for quicker response, use:\n",
    "n_folds = 4\n",
    "backtest_specs = dict(n_folds=n_folds, training_horizons=[24])\n",
    "print(\"n_folds:\", n_folds)\n",
    "\n",
    "results = dict()\n",
    "# Catch warnings for readibility\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    # Write settings to yaml\n",
    "    with open(result_path / \"configs.yaml\", \"w\") as file:\n",
    "        documents = yaml.dump({**shared_pj_elements, **backtest_specs}, file)\n",
    "\n",
    "    for i, config in enumerate(tqdm(backtest_configs)):\n",
    "        # prep input\n",
    "        input_df = shared_input_data.copy(deep=True).rename(\n",
    "            columns=dict(Uncurtailed_true=\"load\")\n",
    "        )\n",
    "        for additional_feature in config[\"additional_features\"]:\n",
    "            input_df = input_df.merge(\n",
    "                additional_feature, left_index=True, right_index=True\n",
    "            )\n",
    "\n",
    "        pj = PredictionJobDataClass(\n",
    "            id=i,  # id and name should be different for each backtest\n",
    "            name=config[\"name\"],\n",
    "            **shared_pj_elements,\n",
    "        )\n",
    "        modelspecs = ModelSpecificationDataClass(id=pj[\"id\"])\n",
    "\n",
    "        # perform the actual backtest\n",
    "        (\n",
    "            forecast,\n",
    "            model,\n",
    "            train_data,\n",
    "            validation_data,\n",
    "            test_data,\n",
    "        ) = train_model_and_forecast_back_test(\n",
    "            pj,\n",
    "            modelspecs=modelspecs,\n",
    "            input_data=input_df,\n",
    "            **backtest_specs,\n",
    "        )\n",
    "\n",
    "        # Write forecast to csv\n",
    "        forecast.to_csv(result_path / f'results_{config[\"name\"]}.csv')\n",
    "        train_data[0].to_csv(result_path / f'train_{config[\"name\"]}.csv')\n",
    "        validation_data[0].to_csv(result_path / f'validation_{config[\"name\"]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bfdc7-701c-4585-a9bd-440f0c981fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a29a8bd-2b95-4b98-8fe6-38955638f7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_28.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecast[[\"forecast\", \"realised\"]].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd863697-9320-4ec3-9fbd-4c90e0155947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd9c844e-26ae-4370-bcdd-ae26359aa379",
   "metadata": {},
   "source": [
    "## Explorative plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12c2aeb1-343c-4b61-8a57-c5e89f2d97a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_29.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for horizon in set(forecast.horizon):\n",
    "    fig = forecast.loc[\n",
    "        forecast.horizon == horizon,\n",
    "        [\n",
    "            \"quantile_P10\",\n",
    "            \"quantile_P30\",\n",
    "            \"quantile_P50\",\n",
    "            \"quantile_P70\",\n",
    "            \"quantile_P90\",\n",
    "            \"realised\",\n",
    "            \"forecast\",\n",
    "        ],\n",
    "    ].iplot(asFigure=True, title=f\"Horizon: {horizon}\")\n",
    "    fig.update_traces(\n",
    "        line=dict(color=\"green\", width=1),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(0, 255, 0, 0.1)\",\n",
    "        selector=lambda x: \"quantile\" in x.name and x.name != \"quantile_P10\",\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        line=dict(color=\"green\", width=1), selector=lambda x: \"quantile_P10\" == x.name\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        line=dict(color=\"red\", width=2), selector=lambda x: \"realised\" in x.name\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        line=dict(color=\"blue\", width=2), selector=lambda x: \"forecast\" in x.name\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525562d-1554-465c-9a33-b71162f410c3",
   "metadata": {},
   "source": [
    "## Plot relation WeatherFeatures and Observed Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4aaa30d-df78-4e33-946f-65395c210be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_31.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Present relations between prediction weather and observed generation\n",
    "wdf = shared_input_data[[\"radiation\", \"windspeed_100m\"]].merge(\n",
    "    -1 * wind_ref, left_index=True, right_index=True\n",
    ")\n",
    "wdf = wdf.merge(-1 * pv_ref, left_index=True, right_index=True)\n",
    "# drop na\n",
    "wdf = wdf.dropna()\n",
    "fig_layout = dict(\n",
    "    width=400, height=300, template=\"plotly_white\", margin=dict(t=0, b=0, l=0, r=0)\n",
    ")\n",
    "# TODO Maybe size the markers wrt the (absolute) value of the load?\n",
    "\n",
    "# Part of timeseries for general overview\n",
    "wdf.resample(\"1H\").mean()[\"2021-04-06\":\"2021-04-10\"].iplot(\n",
    "    y=\"radiation\", secondary_y=\"PV_reference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "15f4d5f6-c15a-417c-b267-c6dcf3753035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rad MAE: 0.27\n"
     ]
    }
   ],
   "source": [
    "rad_data = wdf.apply(lambda x: x / x.max())\n",
    "rad_data = rad_data[wdf.PV_reference > 0.1]\n",
    "rad_fig = rad_data.iplot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"radiation\",\n",
    "    y=\"PV_reference\",\n",
    "    mode=\"markers\",\n",
    "    size=1.5,\n",
    "    layout=fig_layout\n",
    "    | dict(\n",
    "        width=320,\n",
    "        height=300,\n",
    "        margin=dict(t=0, b=0, l=0, r=0),\n",
    "        xaxis=dict(\n",
    "            title=\"Forecasted GHI [normalized]\", tickvals=[0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"PV Reference [normalized]\", tickvals=[0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "        ),\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    asFigure=True,\n",
    ")\n",
    "# Add linear relation\n",
    "rad_fig.add_scatter(x=[0, 1], y=[0, 1], name=\"linear\", mode=\"lines\")\n",
    "\n",
    "rad_fig.write_image(\"output/figs/rad_fig.svg\")\n",
    "# Calculate MAE for Radiation, where PV_ref (normalized) > 0.1\n",
    "rad_threshold = 0.1\n",
    "rad_mae = rad_data.diff(axis=1).iloc[:, 1].abs().mean()\n",
    "print(f\"Rad MAE: {rad_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b069626c-4004-4ee5-80a3-a2df0f2674bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_89.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Repeat for windspeed\n",
    "# Part of timeseries for general overview\n",
    "wdf.resample(\"1H\").mean()[\"2021-04-06\":\"2021-04-10\"].iplot(\n",
    "    y=\"windspeed_100m\", secondary_y=\"Wind_reference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e964ddc2-0947-468e-abd6-99405d1eef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"340px\"\n",
       "    height=\"320\"\n",
       "    src=\"iframe_figures/figure_104.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# fit sigmoid\n",
    "def sigmoid(x, L, x0, k, b):\n",
    "    y = L / (1 + np.exp(-k * (x - x0))) + b\n",
    "    return y\n",
    "\n",
    "\n",
    "# Normalize the windgeneration\n",
    "norm_wind = wdf.copy()\n",
    "norm_wind.Wind_reference /= norm_wind.Wind_reference.max()\n",
    "\n",
    "p0 = [\n",
    "    max(norm_wind.Wind_reference),\n",
    "    np.median(norm_wind.windspeed_100m),\n",
    "    1,\n",
    "    min(norm_wind.Wind_reference),\n",
    "]  # this is an mandatory initial guess\n",
    "popt, pcov = curve_fit(\n",
    "    sigmoid,\n",
    "    norm_wind[norm_wind.Wind_reference > 0].windspeed_100m,\n",
    "    norm_wind[norm_wind.Wind_reference > 0].Wind_reference,\n",
    "    p0,\n",
    "    method=\"dogbox\",\n",
    ")\n",
    "r2 = r2_score(norm_wind.Wind_reference, sigmoid(norm_wind.windspeed_100m, *popt))\n",
    "\n",
    "fig2 = (\n",
    "    norm_wind.resample(\"1H\")\n",
    "    .mean()\n",
    "    .iplot(\n",
    "        x=\"windspeed_100m\",\n",
    "        y=\"Wind_reference\",\n",
    "        asFigure=True,\n",
    "        mode=\"markers\",\n",
    "        size=1.5,\n",
    "        layout=fig_layout\n",
    "        | dict(\n",
    "            xaxis=dict(title=\"Forecasted windspeed 100m [m/s]\"),\n",
    "            yaxis=dict(title=\"Wind Reference [normalized]\"),\n",
    "            width=320,\n",
    "            height=300,\n",
    "            margin=dict(t=0, b=0, l=0, r=0),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add fit\n",
    "xs = np.linspace(0, 33, 100)\n",
    "fig2.add_scatter(x=xs, y=sigmoid(xs, *popt), name=\"fit\", mode=\"lines\")\n",
    "# fig2.add_annotation(x=0.08, xref='paper', y=0.95, yref='paper', text=f'R<sup>2</sup>: {r2:.2f}', showarrow=False)\n",
    "fig2.show()\n",
    "\n",
    "fig2.write_image(\"output/figs/wind_fig.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7d81b-766c-499d-aa13-f6ec997b8aa7",
   "metadata": {},
   "source": [
    "## Effect of curtailments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654103a4-eb0c-4ccb-93ac-fa7b4e9b2c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_22.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Effect of curtailments\n",
    "hal[[\"Uncurtailed_true\", \"Obs\"]].iplot(\n",
    "    kind=\"hist\",\n",
    "    layout=dict(\n",
    "        yaxis=dict(type=\"log\", title=\"Count of periods [log]\"),\n",
    "        xaxis=dict(title=\"Load on Hallum [MW, 5min average]\"),\n",
    "        title=\"Effect of curtailment on load Hallum<br>Note that almost all the negative extremes are effectively reduced, while reducing the rest minimally\",\n",
    "        template=\"plotly_white\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fad1192b-5dc0-4c70-a760-3afebb2d1d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"420px\"\n",
       "    height=\"320\"\n",
       "    src=\"iframe_figures/figure_23.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nomargins = dict(t=0, b=0, l=0, r=0)\n",
    "curtailment_threshold = -10\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# make a subplot with histogram of uncurtailed_moments on the right\n",
    "\n",
    "fig = (\n",
    "    hal[hal[\"Uncurtailed_true\"] != hal[\"Obs\"]][[\"Uncurtailed_true\", \"Obs\"]]\n",
    "    .rename(columns=dict(Obs=\"After curtailment\"))\n",
    "    .iplot(\n",
    "        x=\"Uncurtailed_true\",\n",
    "        y=\"After curtailment\",\n",
    "        mode=\"markers\",\n",
    "        layout=dict(\n",
    "            template=\"plotly_white\",\n",
    "            width=400,\n",
    "            height=300,\n",
    "            margin=nomargins,\n",
    "            xaxis=dict(title=\"Uncurtailed [MW]\"),\n",
    "            yaxis=dict(title=\"Observed after curtailment [MW]\"),\n",
    "        ),\n",
    "        size=3,\n",
    "        asFigure=True,\n",
    "    )\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=[-12, 5], y=[-12, 5], mode=\"lines\", name=\"Without curtailment\", line=dict(width=1)\n",
    ")\n",
    "fig.add_hline(curtailment_threshold, line=dict(width=1))\n",
    "# print('Note that the top figure only shows moments where there was curtailment in the first place. Moments where there was no curtailment are not shown')\n",
    "\n",
    "\n",
    "# Add moments where there could have been curtailment but wasn't\n",
    "should_have_curtailed = hal[\n",
    "    (hal[\"Uncurtailed_true\"] == hal[\"Obs\"]) & (hal[\"Obs\"] < (curtailment_threshold + 2))\n",
    "][[\"Uncurtailed_true\", \"Obs\"]].rename(columns=dict(Obs=\"Uncurtailed moments\"))\n",
    "fig.add_scatter(\n",
    "    x=should_have_curtailed[\"Uncurtailed_true\"],\n",
    "    y=should_have_curtailed[\"Uncurtailed moments\"],\n",
    "    name=\"Uncurtailed moments\",\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=3),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "851c6dbb-5d37-483f-b8de-b1c15f9a84ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"520px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_24.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curt_df = hal[[\"Uncurtailed_true\", \"Obs\"]].copy()\n",
    "curt_df[\"Curtailed moment\"] = hal[\"Uncurtailed_true\"] != hal[\"Obs\"]\n",
    "fig = px.scatter(\n",
    "    curt_df,\n",
    "    x=\"Uncurtailed_true\",\n",
    "    y=\"Obs\",\n",
    "    marginal_x=\"box\",\n",
    "    marginal_y=\"box\",\n",
    "    color=\"Curtailed moment\",\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    dict(\n",
    "        template=\"plotly_white\",\n",
    "        width=500,\n",
    "        height=400,\n",
    "        yaxis=dict(title=\"Observed (after curtailment) [MW]\"),\n",
    "        xaxis=dict(title=\"Load if no curtailment took place [MW]\"),\n",
    "    )\n",
    ")\n",
    "# add linear\n",
    "fig.add_scatter(\n",
    "    x=[-12, 7],\n",
    "    y=[-12, 7],\n",
    "    mode=\"lines\",\n",
    "    showlegend=False,\n",
    "    line=dict(color=\"black\", width=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e079f9f-cdcf-4508-97f1-87257a686dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moments with curtailment = 1.5%\n",
      "Days with curtailment = 4.2%\n"
     ]
    }
   ],
   "source": [
    "percentage = len(hal[hal[\"Uncurtailed_true\"] != hal[\"Obs\"]]) / len(hal)\n",
    "print(f\"Moments with curtailment = {percentage*100:.1f}%\")\n",
    "print(\n",
    "    f\"Days with curtailment = {len(set(hal[hal['Uncurtailed_true']!=hal['Obs']].index.date)) / len(set(hal.index.date))*100:.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57daad-d394-4e65-be65-b6e4af052b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
